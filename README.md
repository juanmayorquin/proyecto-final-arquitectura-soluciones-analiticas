# Proyecto ETL con Apache Hop y PostgreSQL

Este proyecto contiene un flujo de trabajo de integraciÃ³n de datos utilizando **Apache Hop** y una base de datos **PostgreSQL** en contenedor Docker.

---

## ğŸ“‚ Estructura del proyecto

```
â”œâ”€â”€ Analisis-Datacleaner/     # Evidencias de anÃ¡lisis y limpieza de datos
â”œâ”€â”€ Fuentes/                  # Archivos fuente (.csv, etc.)
â”œâ”€â”€ Scripts/                  # Scripts SQL para creaciÃ³n de tablas
â”‚   â”œâ”€â”€ crearElemento.sql
â”‚   â””â”€â”€ crearGlobal.sql
â”œâ”€â”€ Workflow/                 # Flujos de trabajo y pipelines de Apache Hop
â”‚   â”œâ”€â”€ GLOBAL.hwf            # Workflow principal que ejecuta todo en orden
â”‚   â”œâ”€â”€ STG1_ELEMENTO.hpl
â”‚   â”œâ”€â”€ STG1_GLOBAL.hpl
â”‚   â”œâ”€â”€ STG2_ELEMENTO.hpl
â”‚   â”œâ”€â”€ STG3_ELEMENTO.hpl
â”‚   â”œâ”€â”€ FINAL_ELEMENTO.hpl
â”‚   â””â”€â”€ project-config.json
â”œâ”€â”€ metadata/                 # ConfiguraciÃ³n de metadatos de Hop
â”œâ”€â”€ docker-compose.yml        # DefiniciÃ³n de servicios Docker (PostgreSQL)
â””â”€â”€ README.md                 # DocumentaciÃ³n del proyecto
```

---

## ğŸš€ Requisitos previos

* [Docker](https://www.docker.com/) y [Docker Compose](https://docs.docker.com/compose/)
* [Apache Hop](https://hop.apache.org/download/)

---

## ğŸ³ Levantar el contenedor de base de datos

En la raÃ­z del proyecto, ejecutar:

```bash
docker-compose up -d
```

Esto iniciarÃ¡ un contenedor con PostgreSQL en el puerto **5432**.

### Credenciales de conexiÃ³n

* **Host:** localhost
* **Port:** 5432
* **Database:** bd
* **User:** arq
* **Password:** password

---

## ğŸ—„ï¸ CreaciÃ³n de tablas

En la carpeta `Scripts/` se encuentran los archivos SQL necesarios para crear las tablas iniciales:

```bash
psql -h localhost -p 5432 -U arq -d bd -f Scripts/crearElemento.sql
psql -h localhost -p 5432 -U arq -d bd -f Scripts/crearGlobal.sql
```

---

## ğŸ”„ Ejecutar el flujo de Apache Hop

1. Abrir **Apache Hop GUI**.
2. Importar el proyecto seleccionando la carpeta `Workflow/`.
3. Cargar el archivo de configuraciÃ³n `project-config.json`.
4. Ejecutar el **workflow principal**:

   * `GLOBAL.hwf` â†’ este se encarga de correr automÃ¡ticamente todos los pipelines en el orden correcto:

     1. `STG1_GLOBAL.hpl`
     2. `STG1_ELEMENTO.hpl`
     3. `STG2_ELEMENTO.hpl`
     4. `STG3_ELEMENTO.hpl`
     5. `FINAL_ELEMENTO.hpl`

---

## ğŸ“Œ Notas

* AsegÃºrese de que el contenedor de PostgreSQL estÃ© corriendo antes de ejecutar el workflow.
* Los archivos fuente para el proceso ETL se encuentran en la carpeta `Fuentes/`.
* Los anÃ¡lisis y documentaciÃ³n complementaria estÃ¡n en `Analisis-Datacleaner/`.

---
